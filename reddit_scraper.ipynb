{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Reddit Scraper Utility\n",
    "\n",
    "The main driver of this scraper file is the python connector to the Reddit API, coded as praw (Python Reddit API Wrapper).\n",
    "\n",
    "PIL is the Python Imaging Library and is used to more effectively process image data collected from reddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import urllib.request\n",
    "import secret\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the necessary dependencies, I have to make a connection to reddit by calling praw.Reddit() and inputting my API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id=secret.client_id, client_secret=secret.client_secret, user_agent=secret.user_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that we want to collect from Reddit of the subreddit of interest (`sub_reddit`) are the title, score, id, subreddit, link url, number of comments, selftext, and timestamp the post was submitted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                               title  score      id subreddit  \\\n0                    New Releases Thread 5/11 - 5/17     18  ghi2qv  Sneakers   \n1  Due to PUPular demand here are the culprits. S...   2832  gi4lq8  Sneakers   \n2  Missed out on Royal toes this weekend, so I pu...   1411  ghzpfa  Sneakers   \n3                                           Linen 3M    112  gibp4m  Sneakers   \n4               Much better!!! Just feels right now!    471  gi4dhy  Sneakers   \n\n                                                 url  num_comments  \\\n0  https://www.reddit.com/r/Sneakers/comments/ghi...           385   \n1                https://i.redd.it/auw3v9rto9y41.jpg           128   \n2                https://i.redd.it/fppna4lw58y41.jpg            71   \n3                https://i.redd.it/1nsd1g72bcy41.jpg            11   \n4                https://i.redd.it/ch01e1dsl9y41.jpg            39   \n\n                                                body       created  \n0  Please post all your questions, pics and comme...  1.589206e+09  \n1                                                     1.589289e+09  \n2                                                     1.589270e+09  \n3                                                     1.589321e+09  \n4                                                     1.589288e+09  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>score</th>\n      <th>id</th>\n      <th>subreddit</th>\n      <th>url</th>\n      <th>num_comments</th>\n      <th>body</th>\n      <th>created</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>New Releases Thread 5/11 - 5/17</td>\n      <td>18</td>\n      <td>ghi2qv</td>\n      <td>Sneakers</td>\n      <td>https://www.reddit.com/r/Sneakers/comments/ghi...</td>\n      <td>385</td>\n      <td>Please post all your questions, pics and comme...</td>\n      <td>1.589206e+09</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Due to PUPular demand here are the culprits. S...</td>\n      <td>2832</td>\n      <td>gi4lq8</td>\n      <td>Sneakers</td>\n      <td>https://i.redd.it/auw3v9rto9y41.jpg</td>\n      <td>128</td>\n      <td></td>\n      <td>1.589289e+09</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Missed out on Royal toes this weekend, so I pu...</td>\n      <td>1411</td>\n      <td>ghzpfa</td>\n      <td>Sneakers</td>\n      <td>https://i.redd.it/fppna4lw58y41.jpg</td>\n      <td>71</td>\n      <td></td>\n      <td>1.589270e+09</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Linen 3M</td>\n      <td>112</td>\n      <td>gibp4m</td>\n      <td>Sneakers</td>\n      <td>https://i.redd.it/1nsd1g72bcy41.jpg</td>\n      <td>11</td>\n      <td></td>\n      <td>1.589321e+09</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Much better!!! Just feels right now!</td>\n      <td>471</td>\n      <td>gi4dhy</td>\n      <td>Sneakers</td>\n      <td>https://i.redd.it/ch01e1dsl9y41.jpg</td>\n      <td>39</td>\n      <td></td>\n      <td>1.589288e+09</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "number_to_scrape=700\n",
    "sub_reddit = 'Sneakers'\n",
    "posts = []\n",
    "\n",
    "sneakers_subreddit = reddit.subreddit(sub_reddit)\n",
    "\n",
    "for post in sneakers_subreddit.hot(limit=number_to_scrape):\n",
    "    posts.append([  post.title, \n",
    "                    post.score, \n",
    "                    post.id, \n",
    "                    post.subreddit, \n",
    "                    post.url, \n",
    "                    post.num_comments,  \n",
    "                    post.created\n",
    "                ])\n",
    "\n",
    "posts = pd.DataFrame(posts,columns=['title', 'score', 'id', 'subreddit', 'url', 'num_comments', 'created'])\n",
    "\n",
    "posts.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "title            object\nscore             int64\nid               object\nsubreddit        object\nurl              object\nnum_comments      int64\nbody             object\ncreated         float64\ndtype: object"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "posts.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0     2020-05-11 14:10:56\n1     2020-05-12 13:09:00\n2     2020-05-12 08:01:08\n3     2020-05-12 21:57:12\n4     2020-05-12 12:51:57\n              ...        \n695   2020-05-10 16:58:30\n696   2020-05-10 06:01:51\n697   2020-05-10 08:28:30\n698   2020-05-10 18:28:33\n699   2020-05-10 13:03:34\nName: created, Length: 700, dtype: datetime64[ns]"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# convert unix time to a readable datetime format\n",
    "posts['created'] = pd.to_datetime(posts['created'], unit='s')\n",
    "posts['created']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have to convert UNIX time to a more readable datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through all queried posts and download the corresponding image as a jpg file\n",
    "\n",
    "for i in range(1, len(posts['url'])):\n",
    "    try:\n",
    "        urllib.request.urlretrieve(posts['url'][i], \"raw_data/0000\"+str(i)+\".png\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize all of the downloaded images for better scaling effects for the downstream convolutional neural network\n",
    "\n",
    "# Resources used!\n",
    "# https://stackoverflow.com/questions/21517879/python-pil-resize-all-images-in-a-folder\n",
    "# https://kishstats.com/python/2018/04/27/bulk-image-resizing-python.html\n",
    "# https://stackoverflow.com/questions/22282760/filenotfounderror-errno-2-no-such-file-or-directory\n",
    "\n",
    "path = \"/Users/Oliver/GDrive/Data_Scientist_Career/Projects/Hype/raw_data\"\n",
    "\n",
    "for image in os.listdir(path):\n",
    "    try:\n",
    "        current_img = Image.open(path+\"/\"+image)\n",
    "        f, e = os.path.splitext(image)\n",
    "        resize_img = current_img.resize((150,150), Image.ANTIALIAS)\n",
    "        resize_img.save('resized_data/' + f +'-resized.png', 'PNG', quality = 90)\n",
    "    except:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bithypeconda90646dda1eb242bc89cc5427358ff6c8",
   "display_name": "Python 3.7.7 64-bit ('hype': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}